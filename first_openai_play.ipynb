{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\sinea\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (1.13.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sinea\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sinea\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sinea\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\sinea\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from openai) (2.6.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sinea\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\sinea\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\sinea\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sinea\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\sinea\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\sinea\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from httpx<1,>=0.23.0->openai) (2023.5.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sinea\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sinea\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sinea\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\sinea\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sinea\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from tqdm>4->openai) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\sinea\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk = open(\"API key.txt\", \"r\")\n",
    "\n",
    "sk = sk.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"The quick brown fox\"\n",
    "\n",
    "response = openai.completions.create(\n",
    "  model = 'gpt-3.5-turbo-instruct',\n",
    "  prompt=prompt,\n",
    "  max_tokens=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumps over the lazy dog\n",
      "\n",
      "Cops whack floozy jail bid\n",
      "\n",
      "Police arrest a promiscuous woman for attempted escape from jail.\n"
     ]
    }
   ],
   "source": [
    "generated_text = response.choices[0].text.strip()  #return first repsonse of it's output\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요, 어떻게 지내세요?\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, how are you?\"\n",
    "\n",
    "response = openai.completions.create(\n",
    "  model='gpt-3.5-turbo-instruct',\n",
    "  prompt=f\"Translate from English to Korean: {text}\",\n",
    "  max_tokens=50\n",
    ")\n",
    "\n",
    "translation = response.choices[0].text.strip()\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제 이름은 Sinead입니다.\n"
     ]
    }
   ],
   "source": [
    "#How good is it at translating something like my non-english name?\n",
    "\n",
    "text3 = \"My name is Sinead\"\n",
    "\n",
    "response = openai.completions.create(\n",
    "  model='gpt-3.5-turbo-instruct',\n",
    "  prompt=f\"Translate from English to Korean: {text3}\",\n",
    "  max_tokens=50\n",
    ")\n",
    "\n",
    "translation = response.choices[0].text.strip()\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not translate my name presumably as it's not English, let's try with an english name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제 이름은 토마스입니다.\n"
     ]
    }
   ],
   "source": [
    "#How good is it at translating something like my non-english name?\n",
    "\n",
    "text4 = \"My name is Thomas\"\n",
    "\n",
    "response = openai.completions.create(\n",
    "  model='gpt-3.5-turbo-instruct',\n",
    "  prompt=f\"Translate from English to Korean: {text4}\",\n",
    "  max_tokens=50\n",
    ")\n",
    "\n",
    "translation = response.choices[0].text.strip()\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "text2 = \"I love ice cream!\"\n",
    "\n",
    "response = openai.completions.create(\n",
    "  model='gpt-3.5-turbo-instruct',\n",
    "  prompt=f\"Sentiment analysis: {text2}\",\n",
    "  max_tokens=2\n",
    ")\n",
    "\n",
    "sentiment = response.choices[0].text.strip()\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36590]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encode the word for the token \n",
    "from tiktoken import encoding_for_model\n",
    "enc = encoding_for_model('gpt-3.5-turbo-instruct')\n",
    "\n",
    "tokes = enc.encode(sentiment)\n",
    "tokes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Blimey, you're asking the real tough questions, mate! The sky is blue because of a process called Rayleigh scattering, where light from the sun scatters off of molecules in the Earth's atmosphere. But don't worry\n"
     ]
    }
   ],
   "source": [
    "context = \"You are an LLM from London that uses London slang\"\n",
    "\n",
    "question = \"Why is the sky blue?\"\n",
    "\n",
    "response = openai.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=f\"Question answering:\\nContext: {context}\\nQuestion: {question}\",\n",
    "  max_tokens=50\n",
    ")\n",
    "\n",
    "answer = response.choices[0].text.strip()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall, IU has established herself as a successful singer-songwriter and has maintained her popularity and influence in the South Korean music industry.\n",
      "\n",
      "IU's success as a singer-songwriter and her girl next door image have contributed to her popularity and influence in the South\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"With the success of her 2011 albums, Real+ and Last Fantasy, IU established herself as a formidable force on the music charts of her native country and further cemented her girl next door image as Korea's \\\"little sister\\\".[3][4] 2011 also saw her first foray into songwriting with \\\"Hold My Hand\\\", which was written for the television series The Greatest Love. IU's third studio album, Modern Times (2013), showcased a more mature musical style that marked a departure from her earlier girlish image, with several tracks reaching the top 10 on the Gaon Digital Chart. The album was ranked number two on Billboard's \\\"25 Greatest K-Pop Albums of the 2010s\\\" list.[5] IU subsequently exerted more creative control over her music; Chat-Shire marked the first time she was credited as the sole lyricist of her own album.[6] IU's fourth studio album, Palette (2017), became her first to reach number one on Billboard's World Albums chart. While her following records Love Poem and Lilac continued to deviate from mainstream K-pop styles, exploring and mixing various music genres, IU consistently retained her dominance on South Korean music charts.[7][8][9] Her 2020 single \\\"Eight\\\" became her first to reach number one on the Billboard World Digital Song Sales chart.[10]\"\n",
    "\n",
    "response = openai.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=f\"Summarize:\\n{text}\",\n",
    "  max_tokens=50\n",
    ")\n",
    "\n",
    "summary = response.choices[0].text.strip()\n",
    "print(summary)\n",
    "\n",
    "#just givers first 50 tokens rather then finish summarising in 50 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Import necessary libraries\n",
      "import os\n",
      "\n",
      "# Define the path of the folder containing the files\n",
      "folder_path = \"images/\"\n",
      "\n",
      "# Loop through all files in the folder\n",
      "for filename in os.listdir(folder_path):\n",
      "    # Check if the file is a png\n",
      "    if filename.endswith(\".png\"):\n",
      "        # Get the path of the file\n",
      "        filepath = os.path.join(folder_path, filename)\n",
      "        # Convert the file to jpg format\n",
      "        new_filename = filename.replace(\".png\", \".\n"
     ]
    }
   ],
   "source": [
    "description = \"Create a Python script to change a folder of files from png to jpg\"\n",
    "\n",
    "response = openai.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=f\"Code generation:\\n{description}\",\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "code = response.choices[0].text.strip()\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
